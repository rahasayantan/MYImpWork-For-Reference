{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1 -0.41485988323788486, implies as crime rate increases by 1 unit, unit price reduces by 0.41485988323788486 units\n"
     ]
    }
   ],
   "source": [
    "sd_crim = 8.60154511\n",
    "sd_price = 9.197\n",
    "\n",
    "r = -.388\n",
    "\n",
    "B1 = r * sd_price / sd_crim\n",
    "print(\"B1 {}, implies as crime rate increases by 1 unit, unit price reduces by {} units\".format(B1, abs(B1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3284142871333427\n",
      "-0.5013054793424271\n",
      "Price will reduce between 32K and 50K with 95% CI, hence his assumption is correct\n"
     ]
    }
   ],
   "source": [
    "n = 506\n",
    "seb1 = 0.044\n",
    "\n",
    "tcrit = abs(sp.stats.t.ppf(0.025, df = 505))\n",
    "print(B1 + tcrit * seb1)\n",
    "print(B1 - tcrit * seb1)\n",
    "\n",
    "print(\"Price will reduce between 32K and 50K with 95% CI, hence his assumption is correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.3\n",
    "\n",
    "Regression is valid for only the observed ranges. The min value of Crime rate = .0068 > 0. Hence it is incorrect to draw any conclusion about the predicted values of Y for Crim==0 as that value is unobserved.\n",
    "\n",
    "We cannot claim the value will be 24.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.484\n",
      "40.28728266706672\n"
     ]
    }
   ],
   "source": [
    "se = 8.484 #seb1 * sd_crim * (n - 1) ** 0.5\n",
    "print(se)\n",
    "\n",
    "yhat = 24.033 - 0.414 * 1\n",
    "yhat_max = (yhat + tcrit * se)\n",
    "print(yhat_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.44\n",
      "1.2753751103265665\n",
      "0.1010882520004357\n"
     ]
    }
   ],
   "source": [
    "yhat = 22.094 + 6.346\n",
    "print(yhat)\n",
    "\n",
    "t = (40 - yhat)/9.064\n",
    "print(t)\n",
    "\n",
    "print(1 - sp.stats.norm.cdf(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.6 - a\n",
    "\n",
    "From the residual plot we can see that the spread of standardised errors are higher for lower values of standardised prediction compared to higher values.\n",
    "\n",
    "Hence the variance of the residuals are not equal and it demonstrates heteroscedasticity\n",
    "\n",
    "# Q 1.6 - b\n",
    "\n",
    "1. It is a right skewed distribution\n",
    "2. The left tail has less proportaion of data than that of a normal distribution\n",
    "3. Between 40-80 % range the distribution has much less proportion of data compared to a normal distribution\n",
    "\n",
    "From observing the P-P plot we conclude there is considerable difference between this distribution and normal distribution.\n",
    "\n",
    "# Q 1.6 - c\n",
    "\n",
    "Based on the above we can conclude that this regression equation may not be functionally correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.7\n",
    "\n",
    "The increase in R-squared when a new variable is added to a model is the given by the **Square of the Semi-Partial (PART) Correlation**.\n",
    "\n",
    "- From Table 1.7: R-squared @ Step 2 = 0.542\n",
    "- From Table 1.8: PART Correlation for adding RES = -.153 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared in Step 3 is 0.565409\n"
     ]
    }
   ],
   "source": [
    "print(\"R-squared in Step 3 is {}\".format(0.542 + (-.153) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.8\n",
    "\n",
    "It redcuces as there is correlation among RM and CRIM. Part of what was explained by RM in model 1 is now being explained by CRIM in model 2 hence the coefficient value reduces. ==Put in the equations and Graphs in possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 1.9 ==> look again\n",
    "\n",
    "We will use the model in step - 6 for answering this question. \n",
    "\n",
    "- Since the variables are not standardised we cannot use the magnitude of the coefficients as a measure of impact on dependent variable (Price)\n",
    "- We will use the notion of the Standardised Coefficients to measure how much 1 SD change in the variable X (Predictor) changes Y (dependant)\n",
    "\n",
    "- From Tables 1.1 and 1.8 we can easily obtain the Standardised Coefficients for the regression variable and model for all variables except for RM as the SD of RM is not provided in table 1.1 and the Standardised coefficient of RM is not provided in table 1.8. Standardised Coefficient is calculated using: \n",
    "\n",
    "\\begin{equation*} \\beta_{STANDARDISED} = \\hat\\beta * \\frac {S_X} {S_Y}  \\end{equation*}\n",
    "\n",
    "where \\begin{equation*} \\text{Standard Deviation X} = S_X \\end{equation*}\n",
    "& \\begin{equation*} \\text{Standard Deviation Y} = S_Y \\end{equation*}\n",
    "\n",
    "\n",
    "- To calculate the variance of RM we will use the Model 1 and Model 2 from table 1.8. In Model1 the coefficient of RM is 9.102\n",
    "- In Model 2 the coefficient reduces to 8.391 on adding CRIM. This shows there is correlation among CRIM and RM which reduces the coefficient of RM in model 2. We can use the following equation to calculate SD of RM:\n",
    "\n",
    "\\begin{equation*} \\alpha_{RM_{Model1}} = \\beta_{RM_{Model2}} * \\frac{\\beta_{CRIM_{Model2}} * Cor(RM, CRIM)} {Var(RM)}  \\end{equation*}\n",
    "\n",
    "- SD is square root of variance\n",
    "- From tabel 1.2 Cor(RM, CRIM) = -.219, Hence SD of RM = 0.274 \n",
    "- From the below table we can see that **SEZ** has the highest impact on PRICE. SEZ changes 1.24 SD in PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>Standardized Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>-8.993</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RM</td>\n",
       "      <td>7.182</td>\n",
       "      <td>0.213968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.18144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RES</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEZ</td>\n",
       "      <td>4.499</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Highway</td>\n",
       "      <td>-1.154</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.235671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _  Coefficients Standardized Coefficients\n",
       "0  INTERCEPT        -8.993                          \n",
       "1         RM         7.182                  0.213968\n",
       "2       CRIM        -0.194                  -0.18144\n",
       "3        RES        -0.318                    -0.238\n",
       "4        SEZ         4.499                      1.24\n",
       "5    Highway        -1.154                     0.208\n",
       "6        AGE        -0.077                 -0.235671"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\"_\": [\"INTERCEPT\",\"RM\",\"CRIM\",\"RES\",\"SEZ\",\"Highway\", \"AGE\"]})\n",
    "data[\"Coefficients\"] = [-8.993, 7.182, -.194, -.318, 4.499, -1.154, -.077]\n",
    "data[\"Standardized Coefficients\"] = ['', 7.182 * .274 / 9.197, -.194 * 8.60154511 / 9.197, \n",
    "                                     -.238, 1.24, .208, \n",
    "                                     -.077 * 28.1489 / 9.197]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.1\n",
    "\n",
    "1. The model explains 42.25% of variation in box office collection.\n",
    "2. There are outliers in the model.\n",
    "3. The residuals do not follow a normal distribution.\n",
    "4. The model cannot be used since R-square is low.\n",
    "5. Box office collection increases as the budget increases.\n",
    "\n",
    "\n",
    "1, 2, 3 are right ==> color / highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42250000000000004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".65**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.2\n",
    "\n",
    "Here Budget (X) can never be = 0, as it may not be possible to produce a movie without money and X = 0 is unobserved i.e. X = 0 falls outside the domain of the observed values of the variable X. The relationship between the variables can change as we move outside the observed region. We cannot predict for a point that is outside the range of observed values that you used to fit the regression model. \n",
    "\n",
    "The Model explains the relationship between Y and X within the range of onserved values. Hence Mr Chellapa's observation is incorrect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.3 == check again?\n",
    "\n",
    "Since the variable is insignificant at alpha = 0.05, hence the coefficient may not be different from zero. There is is no guranty that the collection of movie released in Releasing_Time Normal_Season is different from Releasing_Time Holiday_Season (which is factored in the intercept / constant).\n",
    "\n",
    "We will calculate both the values with coefficient = 0 & coefficient =.147. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With beta = .147 y = 2.832\n",
      "With beta = 0 y = 2.685\n"
     ]
    }
   ],
   "source": [
    "y = 2.685 + .147\n",
    "print(\"With beta = .147 y = {}\".format(y))\n",
    "print(\"With beta = 0 y = {}\".format(2.685))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.4 == check again?\n",
    "\n",
    "The beta for Release Normal Time is being considered as 0 as it is statistically insignificant at alpha. Hence it will be factored in the Intercept term. Releasing_Time Long_Weekend is statistically significant and the coefficient = 1.247. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max B can be 2.4018319999999997\n",
      "Min B can be 0.09216800000000025\n",
      "Movies released in Long Wekends may earn upto 2.4 lac more than movies released in normal season.\n",
      "Mr. Chellapa's statement is statistically incorrect.\n"
     ]
    }
   ],
   "source": [
    "Bmax = 1.247 + 1.964 *.588\n",
    "print(\"Max B can be {}\".format(Bmax))\n",
    "Bmin = 1.247 - 1.964 *.588\n",
    "print(\"Min B can be {}\".format(Bmin))\n",
    "print(\"Movies released in Long Wekends may earn upto 2.4 lac more than movies released in normal season.\")\n",
    "print(\"Mr. Chellapa's statement is statistically incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.5\n",
    "\n",
    "The increase in R-squared when a new variable is added to a model is the given by the **Square of the Semi-Partial (PART) Correlation**.\n",
    "\n",
    "- From Table 2.5 : R-squared @ Step 5 = 0.810 ** 2 = .6561\n",
    "- From Table 2.6: PART Correlation for adding Director_CAT C = -.104 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared in Step 3 is {}\".format(0.6561 + (-.104) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.6 ==> Need to relook at this\n",
    "\n",
    "- Budget_35_Cr is the highest imapct - spend more than 35 Cr >> lame observation, need to look deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.7\n",
    "\n",
    "- We cannot say that the variables have no relationship to Y (BOX Office Collection)\n",
    "- We can conclude that in presence of the other variables the variables in Model 2 are not explaining additional\n",
    "- Talk about the t-values for each variables etc. more cexplanation\n",
    "\n",
    "Information about Y >> Formulate more nicely (charts and graphs are needed - Venn Diagram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "x =10\n",
    " \n",
    "# Make the diagram\n",
    "venn3(subsets = (x, 10, 10, 10, 10,10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 2.8\n",
    "\n",
    "We are making the assumption that the variable Youtube views imply views of the actual movie and not the trailers before movie release dates. The following explanation will not be valid in that case. Also, we are assuming that revenue collected from advertisements during Youtube views do not fall under the Box Office Collection.\n",
    "\n",
    "Youtube_Views = Will not contribute anything meaningful functionally to the Box Office collection as the movie has been created and released in theaters and all possible collection is completed. The main essence of the prediction here is to understand before making a movie, what all factors may lead to better revenue collection for a movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3.1\n",
    "\n",
    "- **Observations** (N) = 543\n",
    "- **Standard Error**\n",
    "    - \\begin{equation*} SE = \\sqrt {\\frac{ \\sum_{k=1}^N {(Y_k - \\hat{Y_k})^2}} {N - 2}} \\end{equation*}\n",
    "\n",
    "      \\begin{equation*} (Y_k - \\hat{Y_k})^2 = \\epsilon_k^2 = \\text{Residual SS (SSE)} = \\text{17104.06 (Table 3.2)}\\end{equation*}\n",
    "\n",
    "\n",
    "- **R-Squared** = 1 - SSE / SST\n",
    "    - SSE = 17104.06 (Table 3.2)\n",
    "    - SST = 36481.89 (Table 3.2)\n",
    "\n",
    "\n",
    "\n",
    "- **Adjuated R-Squared** = 1 - (SSE / N-k-1) / (SST/N-1)\n",
    "    - N = 543\n",
    "    - K = 3\n",
    "\n",
    "\n",
    "\n",
    "- **Multiple R** = \\begin{equation*} \\sqrt R_{Squared}\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"Multiple R\", \"R Square\", \"Adjusted R Squared\", \"Standard Error\", \"Observations\"]\n",
    "data = pd.DataFrame({\"Regression Statistics\": x})\n",
    "data[\"_\"] = [(1 - 17104.06/36481.89) ** 0.5,1 - 17104.06/36481.89, 1 - (17104.06/(543 - 3 -1))/(36481.89/542),((17104.06)/541) ** 0.5,543]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3.2\n",
    "\n",
    "- **DF Calculation**\n",
    "    - DF for Regression (K) = Number of variables = 3\n",
    "    - DF for Residual = N - K - 1 = 539\n",
    "\n",
    "\n",
    "- **SS Calculation**\n",
    "    - Residual SS (SSE) = 17104.06 (given)\n",
    "    - Total SS (TSS)= 36481.89 (given)\n",
    "    - Regression SS (SSR) = TSS - SSE = 19377.83\n",
    "\n",
    "\n",
    "- **MS Calculation**\n",
    "    - MSR (Regression) = SSR / DF for SSR (=3)\n",
    "    - MSE (Error) = SSE / DF for SSE (= 539)\n",
    "\n",
    "\n",
    "- **F Claculation**\n",
    "    - F = MSR / MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"Regression\", \"Residual\", \"Total\"]\n",
    "ss = [36481.89 - 17104.06, 17104.06,36481.89]\n",
    "df = [3, 539,542]\n",
    "ms = [19377.83 / 2, 17104 / 539, '']\n",
    "f = [(19377.83 / 2) / (17104 / 539),'','']\n",
    "sf = [1 - sp.stats.f.cdf(305, 3, 539),'','']\n",
    "\n",
    "data = pd.DataFrame({\"_\": x})\n",
    "data[\"DF\"] = df\n",
    "data[\"SS\"] = ss\n",
    "data[\"MS\"] = ms\n",
    "data[\"F\"] = f\n",
    "data[\"SignificanceF\"] = sf\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3.3 - Coefficients\n",
    "\n",
    "- MLR T-Test\n",
    "    - \\begin{equation*} t_i = \\frac {\\beta_i - 0} {Se(\\beta_i)}\\end{equation*}\n",
    "    where i denotes the different variables (here i = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"_\":[\"Intercept\", \"Margin\", \"Gender\", \"College\"]})\n",
    "data[\"Coefficeints\"] = [38.59235, 5.32e-05, 1.551306, -1.47506]\n",
    "data[\"Standard Error\"] = [0.937225, 2.18e-06, 0.777806, 0.586995]\n",
    "data[\"t Stat\"] = [(38.59235 / 0.937225),5.32e-05 /  2.18e-06, 1.551306/0.777806, -1.47506/ 0.586995]\n",
    "data[\"P-Value\"] = ['','','','']\n",
    "data[\"Lower 95%\"] = [36.75129, 4.89E-05, 0.023404, -2.62814]\n",
    "data[\"Upper 95%\"] = [40.4334106,5.7463E-05,3.07920835,-0.3219783]\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.2\n",
    "\n",
    "From the table above we see that for all the variables the t-value > 1.964. hence all the variables are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.3\n",
    "\n",
    "F-distribution with DF = 3, 539 at significance = 95% is 2.621. Hence the  model is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - sp.stats.f.cdf(2.621, 3, 539)\n",
    "sp.stats.f.ppf(0.95, 3, 539)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.4\n",
    "\n",
    "The increase in R-squared when a new variable is added to a model is the given by the **Square of the Semi-Partial (PART) Correlation**.\n",
    "\n",
    "- R-squared for Model 2 = 0.52567 (R1)\n",
    "- R-squared for Model 3 = 0.531163 (R2)\n",
    "\n",
    "Part Correlation of College & % Votes = \\begin{equation*}\\sqrt{R_2 - R_1} \\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Increase in R-Squared due to adding College = {}\".format(0.531163 - 0.52567))\n",
    "print(\"Part Correlation of College & % Votes = {}\".format((0.531163 - 0.52567)**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.5\n",
    "\n",
    "We will conduct Partial F-test between models to test for significance of each model. We make the assumption that the variables added are significant at each step (model) at alpha 0.05\n",
    "\n",
    "\\begin{equation*}F_{PARTIAL} = \\frac{\\frac{R_{FULL}^2 - R_{PARTIAL}^2} {k - r}}  {\\frac{1 - R_{FULL}^2} {N - k - 1}}\\end{equation*}\n",
    "\n",
    "where k = variables in full model,\n",
    "      r = variables in reduced model,\n",
    "      N = Total number of records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_partial(rf, rp, n, k, r):\n",
    "    return ((rf **2 - rp ** 2)/(k-r))/((1 - rf ** 2)/ (n - k - 1))\n",
    "\n",
    "print(\"Model 3 Partial F {}\".format(f_partial(0.531163, 0.52567, 543, 3, 2)))\n",
    "print(\"Model 3 Critical F at Df = (1, 539) {}\".format(1 - sp.stats.f.cdf(4.36, 1, 539)))\n",
    "print(\"Model 4 Partial F {}\".format(f_partial(0.56051, 0.531163, 543, 4, 3)))\n",
    "print(\"Model 4 Critical F at Df = (1, 539) {}\".format(1 - sp.stats.f.cdf(25.13, 1, 539)))\n",
    "print(\"Model 5 Partial F {}\".format(f_partial(0.581339, 0.56051, 543, 5, 4)))\n",
    "print(\"Model 5 Critical F at Df = (1, 539) {}\".format(1 - sp.stats.f.cdf(19.29, 1, 539)))\n",
    "\n",
    "print(\"\\nHence we can see that all the models are significant. The number of features (5) are not very high, hence we conclude it's justified to add the additional variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 3.6\n",
    "\n",
    "- Since the variables are not standardised we cannot use the magnitude of the coefficients as a measure of impact on dependent variable (Vote %)\n",
    "- We will use the notion of the Standardised Coefficients to measure how much 1 SD change in the variable X (Predictor) changes Y (dependant)\n",
    "\n",
    "- From the below table we can see that **MARGIN** has the highest impact on Vote %. 1 SD change in Margin changes .75 SD in Vote %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"_\": [\"INTERCEPT\",\"MARGIN\",\"Gender\",\"College\",\"UP\",\"AP\"]})\n",
    "data[\"Coefficients\"] = [38.56993, 5.58E-05, 1.498308, -1.53774, -3.71439, 5.715821]\n",
    "data[\"Standard deviation\"] = ['', 111365.7, 0.311494, 0.412796, 0.354761, 0.209766]\n",
    "data[\"Standardized Coefficients\"] = ['', 5.58E-05 * 111365.7 / 8.204253, 1.498308 * 0.311494 / 8.204253,\n",
    "                                     -1.53774 * 0.412796 / 8.204253, -3.71439 * 0.354761 / 8.204253, \n",
    "                                     5.715821 * 0.209766 / 8.204253]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = 353+692\n",
    "negatives = 751+204\n",
    "\n",
    "N = positives + negatives\n",
    "\n",
    "print(\"Total Positives: {}  ::  Total Negatives: {}  ::  Total Records: {}\".format(positives, negatives, N))\n",
    "\n",
    "pi1 = positives / N\n",
    "pi2 = negatives / N\n",
    "\n",
    "print(\"P(Y=1) = positives / N = {}  ::  P(Y=0) = negatives /N = {}\".format(pi1, pi2))\n",
    "\n",
    "_2LL0 = -2* (negatives * np.log(pi2) + positives * np.log(pi1))\n",
    "print(\"-2LL0 = {}\".format(_2LL0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- -2LLo is called the \"Null Deviance\" of a model. It is -2 Log Likelihooh of a model which had no predictor variables. Hence we obtain the probabilities of positive and negative in the dataset using the frequencies for such model.\n",
    "\n",
    "- After adding \"Premium\" 2LL reduces to 2629.318 (Table 4.2). Hence reduction is equal to (-2LLo -(-2LLm)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2768.537 - 2629.318)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Positive :Actually Positive and Predicted Positive = {}\".format(692))\n",
    "print(\"False Positive :Actually Negative and Predicted Positive = {}\".format(204))\n",
    "\n",
    "print(\"Precision = True Positive / (True Positive + False Positive) = {}\".format(692 / (692 + 204)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.3\n",
    "\n",
    "exp(B) = change in odds ratio. The odds ratio can be interpreted as the multiplicative adjustment to the odds of the outcome, given a **unit** change in the independent variable. In this case the unit of measurement for Premium (1 INR) which is very small compared to the actual Premium (1000s INR), hence a unit change does not lead to a meaningful change in odds ratio, subsequently the odds ratio will be very close to one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The model predicts 751 + 353 = {} customers have a probability less than 0.5 of paying premium\".format(\n",
    "    751+353))\n",
    "print(\"The will call 1104 customers through Call Center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.5 ## Write the formula etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 60\n",
    "fp = 20\n",
    "\n",
    "fn = 51*20\n",
    "tn = 43 * 20\n",
    "\n",
    "total = tp + fp + fn + tn\n",
    "total\n",
    "\n",
    "sensitivity = tp/ (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "recall = sensitivity\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "print(\"Precision {} :: \\nRecall {} :: \\nsensitivity {} :: \\nspecificity {} ::\".format(precision, recall, sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.6\n",
    "\n",
    "Probability can be calculated using the following formula:\n",
    "\n",
    "\\begin{equation*} P(Y=1) = \\frac{\\exp^z} {1 + \\exp^z}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*} \\text{where z} = \\beta_0 + \\beta_1 * Salaried + \\beta_2 * HouseWife +\\beta_3 * others\\end{equation*}\n",
    "\n",
    "However in this case the variable Housewife is not a significant variable. Hence using this equation to calculate probability for the variable house wife may not be appropriate. However we will procced to compute the probability using the equation, using the coefficient in the equation and also using the coefficient as 0 (B is not significantly different from 0 for insignificant variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Probability of House wife paying the Premium is (beta ==22.061): {}\".format(np.exp(-.858 + 22.061)\n",
    "                                                                    / (1 + np.exp(-.858 + 22.061))))\n",
    "\n",
    "print(\"Probability of House wife paying the Premium is (beta = 0): {}\".format(np.exp(-.858 + 0)\n",
    "                                                                    / (1 + np.exp(-.858 + 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.7\n",
    "\n",
    "The Constant / Intercept measures for people with the following occupations **Professionals, Business and Agriculture** and they have a lower probability of renewal payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.8\n",
    "\n",
    "Probability can be calculated using the following formula:\n",
    "\n",
    "\\begin{equation*} P(Y=1) = \\frac{\\exp^z} {1 + \\exp^z}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*} \\text{where z} = constant + \\beta_1 * Policy Term\\end{equation*}\n",
    "\n",
    "SSC Education, Agriculturist Profession & Marital Status Single will be factored in the term constant of the given equation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Probability : {}\".format(np.exp(3.105 + 60 * -0.026)/ (1 + np.exp(3.105 + 60 * -0.026))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.9\n",
    "\n",
    "The coefficients tell about the relationship between the independent variables and the dependent variable, where the dependent variable is on the logit scale.  These estimates tell the amount of increase in the predicted log odds that would be predicted by a 1 unit increase in the predictor, holding all other predictors constant.\n",
    "\n",
    "**Recommendations** :\n",
    "\n",
    "- Married People has higher possibility of renewals (log odds ratio increases)\n",
    "- As payment term increases it leads to slightly reduced log odds of renewals\n",
    "- Professionals, Business men have much higher chance of defaulting on log odds of renewals\n",
    "- Being a graduate does increase the chance of log odds of renewals\n",
    "- Annual / Half yearly / Quarterly policy renewal schemes see reduced log odds of renewals\n",
    "- Model Change - Premuim : Variable scale should be changed for better understanding of Premium's contribution to affinity to renew policy (may be reduce unit to 1000s)\n",
    "\n",
    "\n",
    "- Strategy:\n",
    "    - For new customers target Married people and graduates\n",
    "    - For existing customers send more reminders (via Call centers / messgaes etc) to Business men, Professionals for renewal\n",
    "    - For people paying premiums in yearly / quarterly / halfyearly terms, send reminders to them before renewal dates\n",
    "    - For people with long payment terms keep sending them payment reminders as the tenure of their engagement increases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 4.10\n",
    "\n",
    "Gain is calculated as:\n",
    "\n",
    "\\begin{equation*} gain = \\frac {\\text{cumulative number of positive obs upto decile i}} \n",
    "{\\text {Total number of positive observations}} \\end{equation*}\n",
    "\n",
    "Lift is calculated as:\n",
    "\n",
    "\\begin{equation*} lift = \\frac {\\text{cumulative number of positive obs upto decile i}} \n",
    "{\\text {Total number of positive observations upto decile i from random model}} \\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Decile': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]})\n",
    "data['posunits'] = [31, 0, 0, 0, 3, 5, 5, 4, 2, 1]\n",
    "data['negunits'] = [0, 0, 0, 0, 0, 5, 11, 17, 12, 2]\n",
    "data['posCountunits'] = data['posunits'] * 20\n",
    "data['negCountunits'] = data['negunits'] * 20\n",
    "avgPerDec = np.sum(data['posCountunits']) / 10\n",
    "data['avgCountunits'] = avgPerDec\n",
    "\n",
    "data['cumPosCountunits'] = data['posCountunits'].cumsum()\n",
    "data['cumAvgCountunits'] = data['avgCountunits'].cumsum()\n",
    "data['lift'] = data['cumPosCountunits'] / data['cumAvgCountunits']\n",
    "data['gain'] = data['cumPosCountunits'] / data['posCountunits'].sum()\n",
    "\n",
    "data['avgLift'] = 1\n",
    "\n",
    "\n",
    "#print(df)\n",
    "#### Plots\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(data.avgLift, 'r-', label='Average Model Performance')\n",
    "plt.plot(data.lift, 'g-', label='Predict Model Performance')\n",
    "plt.title('Cumulative Lift Chart')\n",
    "plt.xlabel('Deciles')\n",
    "plt.ylabel('Normalised Model')\n",
    "plt.legend()\n",
    "plt.xlim(0, 10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(data.Decile, 'r-', label='Average Model Performance')\n",
    "plt.plot(data.gain, 'g-', label='Predict Model Performance')\n",
    "plt.title('Cumulative Gain Chart')\n",
    "plt.xlabel('Deciles')\n",
    "plt.ylabel('Gain')\n",
    "plt.legend()\n",
    "plt.xlim(0, 10)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaions**\n",
    "\n",
    "- This ia a good model\n",
    "- From gain we see that the model captures 76% positives by the fifth decile\n",
    "- From Lift we see for the 1st decile model captures 6 times more positives than an ordinary model, 3 times for second decile, 2 times for 3rd decile, 1.5 times for 4th decile and 1.27 times for the 5th decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
