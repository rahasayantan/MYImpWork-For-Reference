{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg as slin\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPM = np.array([\n",
    "    [0.5, 0.3, .1, .1],\n",
    "    [0.1, 0.5, 0.2, 0.2],\n",
    "    [0.2, 0.1, 0.5, 0.2],\n",
    "    [0.1, 0.1, 0.3, 0.5]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = [0, 1, 2, 3, 4, 5, 6, 7] \n",
    "# states are (0, .1) => buy @.1, (0, 1)=> buy @1, ((0,2), 0,3)\n",
    "# states are (1, .1) => sell @.1, (1, 1)=> sell @1, ((1,2), 1,3)\n",
    "action = [0, 1, 2] # 0= do nothing, 1 = buy, 2=sell @ above states\n",
    "\n",
    "action_cost = np.array([\n",
    "    [.1],\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [-.1],\n",
    "    [-1],\n",
    "    [-2],\n",
    "    [-3]]\n",
    ")\n",
    "\n",
    "policy_state_transition = [(0,0,0), (1,0,1), (2,0,2), (3,0,3), (0,1,4), (1,1,5), (2,1,6), (3,1,7),\n",
    "                           (4,0,4), (5,0,5), (6,0,6), (7,0,7), (4,2,0), (5,2,1), (6,2,2), (7,2,3),]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the immediate reward matrix for states and actions -- Difficult to make this generic, this has to be modified for every problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0. ],\n",
       "        [-0.1],\n",
       "        [ 0. ]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [-1. ],\n",
       "        [ 0. ]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [-2. ],\n",
       "        [ 0. ]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [-3. ],\n",
       "        [ 0. ]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [ 0. ],\n",
       "        [ 0.1]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [ 0. ],\n",
       "        [ 1. ]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [ 0. ],\n",
       "        [ 2. ]],\n",
       "\n",
       "       [[ 0. ],\n",
       "        [ 0. ],\n",
       "        [ 3. ]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_action_imm_rew(policy_state_transition, action_cost):\n",
    "\n",
    "    state_action = np.zeros((len(state),len(action),1))\n",
    "    state_action_imm_rew = np.array(state_action.copy())\n",
    "    state_action_imm_rew\n",
    "    for s, a, s1 in policy_state_transition:\n",
    "        if (s in  [0,1,2,3]) & (a in [0,2]):\n",
    "            state_action_imm_rew[s,a,:] = 0\n",
    "        elif (s in  [4,5,6,7]) & (a in [0,1]):\n",
    "            state_action_imm_rew[s,a,:] = 0\n",
    "        else:\n",
    "            state_action_imm_rew[s,a,:] = -1 * action_cost[s]\n",
    "        \n",
    "    return state_action_imm_rew\n",
    "        \n",
    "        \n",
    "state_action_imm_rew = state_action_imm_rew(policy_state_transition, action_cost)\n",
    "state_action_imm_rew            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs to test Policy and reward -- Having challenge to incorporate for period for discount factoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LP formulation for MDP -- Unable to make the constraint and matrix formation generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.475 0.285 0.095 0.095]\n",
      " [0.095 0.475 0.19  0.19 ]\n",
      " [0.19  0.095 0.475 0.19 ]\n",
      " [0.095 0.095 0.285 0.475]\n",
      " [0.475 0.285 0.095 0.095]\n",
      " [0.095 0.475 0.19  0.19 ]\n",
      " [0.19  0.095 0.475 0.19 ]\n",
      " [0.095 0.095 0.285 0.475]\n",
      " [0.475 0.285 0.095 0.095]\n",
      " [0.095 0.475 0.19  0.19 ]\n",
      " [0.19  0.095 0.475 0.19 ]\n",
      " [0.095 0.095 0.285 0.475]\n",
      " [0.475 0.285 0.095 0.095]\n",
      " [0.095 0.475 0.19  0.19 ]\n",
      " [0.19  0.095 0.475 0.19 ]\n",
      " [0.095 0.095 0.285 0.475]]\n"
     ]
    }
   ],
   "source": [
    "from pulp import *\n",
    "# initialize the model\n",
    "prob = LpProblem(\"mdp02\", LpMinimize)\n",
    "discount = 0.95\n",
    "#########\n",
    "policy_state_transition = [(0,0,0), (1,0,1), (2,0,2), (3,0,3), (0,1,4), (1,1,5), (2,1,6), (3,1,7),\n",
    "                           (4,0,4), (5,0,5), (6,0,6), (7,0,7), (4,2,0), (5,2,1), (6,2,2), (7,2,3),]\n",
    "\n",
    "transitions = []\n",
    "rewards = []\n",
    "for p, q, r in policy_state_transition:\n",
    "    if r > 3: # custom for this problem\n",
    "        r-= 4\n",
    "    transitions.append(TPM[r])\n",
    "    rewards.append(state_action_imm_rew[p,q])\n",
    "new_mat =np.array(transitions) * discount ** (1)\n",
    "print(new_mat)\n",
    "\n",
    "T = len(state)\n",
    "# ---------------------\n",
    "# VARIABLES\n",
    "# ---------------------\n",
    "\n",
    "dv = LpVariable.dicts(\"dv\", range(0, T), 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mdp02:\n",
       "MINIMIZE\n",
       "1*dv_0 + 1*dv_1 + 1*dv_2 + 1*dv_3 + 1*dv_4 + 1*dv_5 + 1*dv_6 + 1*dv_7 + 0\n",
       "SUBJECT TO\n",
       "_C1: 0.525 dv_0 - 0.285 dv_1 - 0.095 dv_2 - 0.095 dv_3 >= 0\n",
       "\n",
       "_C2: dv_0 - 0.475 dv_4 - 0.285 dv_5 - 0.095 dv_6 - 0.095 dv_7 >= -0.1\n",
       "\n",
       "_C3: - 0.095 dv_0 + 0.525 dv_1 - 0.19 dv_2 - 0.19 dv_3 >= 0\n",
       "\n",
       "_C4: dv_1 - 0.095 dv_4 - 0.475 dv_5 - 0.19 dv_6 - 0.19 dv_7 >= -1\n",
       "\n",
       "_C5: - 0.19 dv_0 - 0.095 dv_1 + 0.525 dv_2 - 0.19 dv_3 >= 0\n",
       "\n",
       "_C6: dv_2 - 0.19 dv_4 - 0.095 dv_5 - 0.475 dv_6 - 0.19 dv_7 >= -2\n",
       "\n",
       "_C7: - 0.095 dv_0 - 0.095 dv_1 - 0.285 dv_2 + 0.525 dv_3 >= 0\n",
       "\n",
       "_C8: dv_3 - 0.095 dv_4 - 0.095 dv_5 - 0.285 dv_6 - 0.475 dv_7 >= -3\n",
       "\n",
       "_C9: 0.525 dv_4 - 0.285 dv_5 - 0.095 dv_6 - 0.095 dv_7 >= 0\n",
       "\n",
       "_C10: - 0.475 dv_0 - 0.285 dv_1 - 0.095 dv_2 - 0.095 dv_3 + dv_4 >= 0.1\n",
       "\n",
       "_C11: - 0.095 dv_4 + 0.525 dv_5 - 0.19 dv_6 - 0.19 dv_7 >= 0\n",
       "\n",
       "_C12: - 0.095 dv_0 - 0.475 dv_1 - 0.19 dv_2 - 0.19 dv_3 + dv_5 >= 1\n",
       "\n",
       "_C13: - 0.19 dv_4 - 0.095 dv_5 + 0.525 dv_6 - 0.19 dv_7 >= 0\n",
       "\n",
       "_C14: - 0.19 dv_0 - 0.095 dv_1 - 0.475 dv_2 - 0.19 dv_3 + dv_6 >= 2\n",
       "\n",
       "_C15: - 0.095 dv_4 - 0.095 dv_5 - 0.285 dv_6 + 0.525 dv_7 >= 0\n",
       "\n",
       "_C16: - 0.095 dv_0 - 0.095 dv_1 - 0.285 dv_2 - 0.475 dv_3 + dv_7 >= 3\n",
       "\n",
       "VARIABLES\n",
       "dv_0 Continuous\n",
       "dv_1 Continuous\n",
       "dv_2 Continuous\n",
       "dv_3 Continuous\n",
       "dv_4 Continuous\n",
       "dv_5 Continuous\n",
       "dv_6 Continuous\n",
       "dv_7 Continuous"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constraints\n",
    "\n",
    "prob += dv[0] >= lpSum([new_mat[0, i] * dv[i] for i in [0,1,2,3]]) + rewards[0]\n",
    "prob += dv[0] >= lpSum([new_mat[4, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[4]\n",
    "\n",
    "prob += dv[1] >= lpSum([new_mat[1, i] * dv[i] for i in [0,1,2,3]]) + rewards[1]\n",
    "prob += dv[1] >= lpSum([new_mat[5,  (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[5]\n",
    "\n",
    "prob += dv[2] >= lpSum([new_mat[2, i] * dv[i] for i in [0,1,2,3]]) + rewards[2]\n",
    "prob += dv[2] >= lpSum([new_mat[6, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[6]\n",
    "\n",
    "prob += dv[3] >= lpSum([new_mat[3, i] * dv[i] for i in [0,1,2,3]]) + rewards[3]\n",
    "prob += dv[3] >= lpSum([new_mat[7, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[7]\n",
    "\n",
    "prob += dv[4] >= lpSum([new_mat[8, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[8]\n",
    "prob += dv[4] >= lpSum([new_mat[12, i] * dv[i] for i in [0,1,2,3]]) + rewards[12]\n",
    "\n",
    "prob += dv[5] >= lpSum([new_mat[9, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[9]\n",
    "prob += dv[5] >= lpSum([new_mat[13, i] * dv[i] for i in [0,1,2,3]]) + rewards[13]\n",
    "\n",
    "prob += dv[6] >= lpSum([new_mat[10, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[10]\n",
    "prob += dv[6] >= lpSum([new_mat[14, i] * dv[i] for i in [0,1,2,3]]) + rewards[14]\n",
    "\n",
    "prob += dv[7] >= lpSum([new_mat[11, (i-4)] * dv[i] for i in [4,5,6,7]]) + rewards[11]\n",
    "prob += dv[7] >= lpSum([new_mat[15, i] * dv[i] for i in [0,1,2,3]]) + rewards[15]\n",
    "\n",
    "# Objective function\n",
    "prob += sum([dv[i] for i in np.arange(T)]), \"Objective\"\n",
    "    \n",
    "\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "dv\n",
      "5.93303\n",
      "5.30852\n",
      "4.7838\n",
      "4.63111\n",
      "6.03303\n",
      "6.30852\n",
      "6.7838\n",
      "7.63111\n",
      "Objective 47.41292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "prob.writeLP(\"mdp02.lp\")\n",
    "    \n",
    "status = prob.solve(GLPK(options=[\"--ranges\",\"mdp02.sen\"]))\n",
    "print(status)\n",
    "\n",
    "#print the result\n",
    "print(\"dv\")\n",
    "for i in range(0, T):\n",
    "    print(dv[i].value())\n",
    "    \n",
    "print(\"Objective\", value(prob.objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mdp02.sen\n",
    "GLPK 4.65 - SENSITIVITY ANALYSIS REPORT                                                                         Page   1\n",
    "\n",
    "Problem:    \n",
    "Objective:  Objective = 47.41291369 (MINimum)\n",
    "\n",
    "   No. Row name     St      Activity         Slack   Lower bound       Activity      Obj coef  Obj value at Limiting\n",
    "                                          Marginal   Upper bound          range         range   break point variable\n",
    "------ ------------ -- ------------- ------------- -------------  ------------- ------------- ------------- ------------\n",
    "     1 _C1          BS        .70750       -.70750        .             1.48947     -25.95034      29.05305 _C2\n",
    "                                            .               +Inf         .44680      32.43772      70.36260 _C4\n",
    "\n",
    "     2 _C10         BS        .80750       -.70750        .10000        3.64882     -14.36013      35.81711 _C9\n",
    "                                            .               +Inf       -1.36500      28.68196      70.57359 _C2\n",
    "\n",
    "     3 _C11         NL        .             .             .             -.29458     -29.16327      38.82211 _C12\n",
    "                                          29.16327          +Inf        3.85263          +Inf     159.76826 _C13\n",
    "\n",
    "     4 _C12         BS       1.43450       -.43450       1.00000        7.11713     -19.77171      19.05040 _C11\n",
    "                                            .               +Inf         .25533      19.46263      75.33206 _C4\n",
    "\n",
    "     5 _C13         BS        .36600       -.36600        .              .77053     -22.10288      39.32326 _C14\n",
    "                                            .               +Inf         .00580      61.07374      69.76590 _C16\n",
    "\n",
    "     6 _C14         NL       2.00000        .            2.00000        1.30286     -11.60401      39.32326 _C13\n",
    "                                          11.60401          +Inf        2.77053          +Inf      56.35411 _C6\n",
    "\n",
    "     7 _C15         BS        .90050       -.90050        .             1.89579     -22.10288      27.50927 _C16\n",
    "                                            .               +Inf         .68090      40.71583      84.07752 _C14\n",
    "\n",
    "     8 _C16         NL       3.00000        .            3.00000        1.28476     -11.60401      27.50927 _C15\n",
    "                                          11.60401          +Inf        4.89579          +Inf      69.41168 _C8\n",
    "\n",
    "     9 _C2          NL       -.10000        .            -.10000       -1.44762     -13.62393      29.05305 _C1\n",
    "                                          13.62393          +Inf        1.38947          +Inf      67.70540 _C10\n",
    "\n",
    "    10 _C3          BS        .43450       -.43450        .              .91474     -17.60905      39.76178 _C4\n",
    "                                            .               +Inf         .29300     143.40979     109.72447 _C2\n",
    "\n",
    "GLPK 4.65 - SENSITIVITY ANALYSIS REPORT                                                                         Page   2\n",
    "\n",
    "Problem:    \n",
    "Objective:  Objective = 47.41291369 (MINimum)\n",
    "\n",
    "   No. Row name     St      Activity         Slack   Lower bound       Activity      Obj coef  Obj value at Limiting\n",
    "                                          Marginal   Upper bound          range         range   break point variable\n",
    "------ ------------ -- ------------- ------------- -------------  ------------- ------------- ------------- ------------\n",
    "    11 _C4          NL      -1.00000        .           -1.00000       -1.82762      -9.24475      39.76178 _C3\n",
    "                                           9.24475          +Inf        -.08526          +Inf      55.86943 _C12\n",
    "\n",
    "    12 _C5          NL        .             .             .             -.24814     -34.49261      38.85407 _C6\n",
    "                                          34.49261          +Inf        2.28684          +Inf     126.29207 _C12\n",
    "\n",
    "    13 _C6          BS      -1.63400       -.36600      -2.00000        1.73909     -23.38482      85.62371 _C5\n",
    "                                            .               +Inf       -3.13483      24.42950       7.49511 _C14\n",
    "\n",
    "    14 _C7          NL        .             .             .             -.61051     -29.08622      29.65553 _C8\n",
    "                                          29.08622          +Inf        2.28684          +Inf     113.92850 _C12\n",
    "\n",
    "    15 _C8          BS      -2.09950       -.90050      -3.00000        1.27359     -19.71947      88.81394 _C7\n",
    "                                            .               +Inf       -3.01450      24.42950      -3.87682 _C16\n",
    "\n",
    "    16 _C9          NL        .             .             .             -.47966     -21.18120      37.25312 _C10\n",
    "                                          21.18120          +Inf        1.92632          +Inf      88.21459 _C13\n",
    "\n",
    "GLPK 4.65 - SENSITIVITY ANALYSIS REPORT                                                                         Page   3\n",
    "\n",
    "Problem:    \n",
    "Objective:  Objective = 47.41291369 (MINimum)\n",
    "\n",
    "   No. Column name  St      Activity      Obj coef   Lower bound       Activity      Obj coef  Obj value at Limiting\n",
    "                                          Marginal   Upper bound          range         range   break point variable\n",
    "------ ------------ -- ------------- ------------- -------------  ------------- ------------- ------------- ------------\n",
    "     1 dv_0         BS       5.93303       1.00000        .             9.54236      -4.62224      14.05595 _C2\n",
    "                                            .               +Inf        5.93303          +Inf          +Inf\n",
    "\n",
    "     2 dv_1         BS       5.30852       1.00000        .             7.11234      -3.68811      22.52598 _C4\n",
    "                                            .               +Inf        5.30852          +Inf          +Inf\n",
    "\n",
    "     3 dv_2         BS       4.78380       1.00000        .            17.56678      -5.17064      17.89380 _C5\n",
    "                                            .               +Inf        4.78380          +Inf          +Inf\n",
    "\n",
    "     4 dv_3         BS       4.63111       1.00000        .            16.08386      -4.80782      20.51627 _C7\n",
    "                                            .               +Inf        4.63111          +Inf          +Inf\n",
    "\n",
    "     5 dv_4         BS       6.03303       1.00000        .            13.83558      -4.22928      15.86451 _C9\n",
    "                                            .               +Inf        6.03303          +Inf          +Inf\n",
    "\n",
    "     6 dv_5         BS       6.30852       1.00000        .            25.18549      -4.95198       9.86477 _C11\n",
    "                                            .               +Inf        6.30852          +Inf          +Inf\n",
    "\n",
    "     7 dv_6         BS       6.78380       1.00000        .             8.48782      -4.24712      11.81752 _C14\n",
    "                                            .               +Inf        6.78380          +Inf          +Inf\n",
    "\n",
    "     8 dv_7         BS       7.63111       1.00000        .            11.77089      -4.31399       6.86128 _C16\n",
    "                                            .               +Inf        7.63111          +Inf          +Inf\n",
    "\n",
    "End of report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikibooks.org/wiki/GLPK/Solution_information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
